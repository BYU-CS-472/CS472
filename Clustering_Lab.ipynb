{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVL7_bgmIAPR"
      },
      "source": [
        "# Unsupervised Learning: Clustering Lab\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZbYjZZZ_yLV"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCcEPx5VIORj"
      },
      "source": [
        "## 1. Implement the HAC and K-means algorithms\n",
        "For both algorithms:\n",
        "- Use euclidean distance as the distance metric\n",
        "- You only need to handle continuous features, but think about how you would handle nominal and unknown data\n",
        "---\n",
        "When reporting the results of each algorithm, include the following:\n",
        "- The number of clusters (*k*)\n",
        "- The silhouette score of the full clustering (You can either write and use your own silhouette_score function (extra credit) or use sklearn's)\n",
        "\n",
        "For each cluster include:\n",
        "- The vectors of points representing the cluster centroid\n",
        "- The number of instances tied to that centroid\n",
        "---\n",
        "\n",
        "### 1.1 HAC (Hierarchical Agglomerative Clustering)\n",
        "\n",
        "### HAC Code requirements \n",
        "- HAC should support both single link and complete link options.\n",
        "- HAC automatically generates all clusterings from *n* to 1.  To reduce the amount of output implement a mechanism to specify for which *k* values actual output will be generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a2KSZ_7AN0G"
      },
      "outputs": [],
      "source": [
        "class HACClustering(BaseEstimator,ClusterMixin):\n",
        "\n",
        "    def __init__(self,k=3,link_type='single'): ## add parameters here\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            k = how many final clusters to have\n",
        "            link_type = single or complete. when combining two clusters use complete link or single link\n",
        "        \"\"\"\n",
        "        self.link_type = link_type\n",
        "        self.k = k\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\" Fit the data; In this lab this will make the K clusters :D\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data\n",
        "            y (array-like): An optional argument. Clustering is usually unsupervised so you don't need labels\n",
        "        Returns:\n",
        "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
        "        \"\"\"\n",
        "        return self\n",
        "    \n",
        "    def print_clusters(self):\n",
        "        \"\"\"\n",
        "            Used for grading.\n",
        "            print(\"Num clusters: {:d}\\n\".format(k))\n",
        "            print(\"Silhouette score: {:.4f}\\n\\n\".format(silhouette_score))\n",
        "            for each cluster and centroid:\n",
        "                print(np.array2string(centroid,precision=4,separator=\",\"))\n",
        "                print(\"{:d}\\n\".format(size of cluster))\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KibCIXIThpbE"
      },
      "source": [
        "### 1.1.1 (15%) Debug \n",
        "\n",
        "Debug your model by running it on the [Debug Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/abalone.arff)\n",
        "\n",
        "\n",
        "---\n",
        "The dataset was modified to be smaller. The last datapoint should be on line 359 or the point 0.585,0.46,0.185,0.922,0.3635,0.213,0.285,10. The remaining points are commented out.\n",
        "\n",
        "- Include the output class (last column) as an additional input feature\n",
        "- Normalize Data--attributes should be normalized using the formula (x-xmin)/(xmax-xmin). Do this exact normalization rather than call the scikit normalization, else you will not get the same answers as us.\n",
        "- Report results for *k* = 5\n",
        "- Use 4 decimal places and DO NOT ROUND when reporting silhouette score and centroid values.\n",
        "\n",
        "---\n",
        "Solutions in files:\n",
        "\n",
        "[Debug HAC Single (Silhouette).txt](https://raw.githubusercontent.com/cs472ta/CS472/master/debug_solutions/Debug%20HAC%20Single%20Link%20%28Silhouette%29.txt)\n",
        "\n",
        "[Debug HAC Complete (Silhouette).txt](https://raw.githubusercontent.com/cs472ta/CS472/master/debug_solutions/Debug%20HAC%20Complete%20Link%20%28Silhouette%29.txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Debug Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY3VNB1ui03N"
      },
      "source": [
        "### 1.1.2 (15%) Evaluation\n",
        "\n",
        "We will evaluate your model based on its print_clusters() output using this [Evaluation Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/seismic-bumps_train.arff) using the *same* parameters as for Debug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg1UE0p3-Jen"
      },
      "source": [
        "#### Complete Link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yAxA78QjDh2"
      },
      "outputs": [],
      "source": [
        "# Load evaluation data\n",
        "# Train on evaluation data using complete link\n",
        "# Print clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQVABkYL-Jeo"
      },
      "source": [
        "#### Single Link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxJ0DA92-Jeo"
      },
      "outputs": [],
      "source": [
        "# Load evaluation data\n",
        "# Train on evaluation data using single link\n",
        "# Print clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ougZHjiL-Jeo"
      },
      "source": [
        "### 1.2 K-means\n",
        "\n",
        "### Code requirements \n",
        "- Ability to choose *k* and specify the *k* initial centroids\n",
        "- Ability to handle distance ties--when a node or cluster has the same distance to another cluster, which should be rare, choose the earliest cluster in your list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNeVvoZl-Jeo"
      },
      "outputs": [],
      "source": [
        "class KMEANSClustering(BaseEstimator,ClusterMixin):\n",
        "\n",
        "    def __init__(self,k=3,debug=False): ## add parameters here\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            k = how many final clusters to have\n",
        "            debug = if debug is true use the first k instances as the initial centroids otherwise choose random points as the initial centroids.\n",
        "        \"\"\"\n",
        "        self.k = k\n",
        "        self.debug = debug\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\" Fit the data; In this lab this will make the K clusters :D\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data\n",
        "            y (array-like): An optional argument. Clustering is usually unsupervised so you don't need labels\n",
        "        Returns:\n",
        "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
        "        \"\"\"\n",
        "        return self\n",
        "    \n",
        "    def print_clusters(self):\n",
        "        \"\"\"\n",
        "            Used for grading.\n",
        "            print(\"Num clusters: {:d}\\n\".format(k))\n",
        "            print(\"Silhouette score: {:.4f}\\n\\n\".format(silhouette_score))\n",
        "            for each cluster and centroid:\n",
        "                print(np.array2string(centroid,precision=4,separator=\",\"))\n",
        "                print(\"{:d}\\n\".format(size of cluster))\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVZID7Nf-Jeo"
      },
      "source": [
        "### 1.2.1 (10%) K-Means Debug \n",
        "\n",
        "Debug your model by running it on the [Debug Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/abalone.arff)\n",
        "\n",
        "- Train until convergence\n",
        "- Make sure to include the output class (last column) as an additional input feature\n",
        "- Normalize Data--attributes should be normalized using the formula (x-xmin)/(xmax-xmin). Do this exact normalization rather than call the scikit nomralization, else you will not get the same answers as us.\n",
        "- Use *k* = 5\n",
        "- Use the first *k* instances in the training set as the initial centroids\n",
        "- Use 4 decimal places and DO NOT ROUND when reporting silhouette score and centroid values\n",
        "\n",
        "---\n",
        "Solution in file:\n",
        "\n",
        "[Debug K Means (Silhouette).txt](https://raw.githubusercontent.com/cs472ta/CS472/master/debug_solutions/Debug%20K%20Means%20%28Silhouette%29.txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgAyy82gixIF"
      },
      "outputs": [],
      "source": [
        "# Load debug data\n",
        "# Train on debug data\n",
        "# Print clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dM7dY52-Jep"
      },
      "source": [
        "### 1.2.2 (15%) K-Means Evaluation\n",
        "\n",
        "We will evaluate your model based on its print_clusters() output using this [Evaluation Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/seismic-bumps_train.arff) using the *same* parameters as for Debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYDNgbmN-Jep"
      },
      "outputs": [],
      "source": [
        "# Load evaluation data\n",
        "# Train on evaluation data\n",
        "# Print clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vWiTdlbR2Xh"
      },
      "source": [
        "## 2. Iris Clustering with Both Alogrithms\n",
        "For both algorithms: \n",
        "- Don't include the output label as one of the input features\n",
        "- Normalize the data\n",
        "- Show your results for clusterings with *k* = 2-7.  \n",
        "- Graph the silhouette score for each *k* and discuss your results (i.e. what kind of clusters are being made).\n",
        "- Load this Iris Dataset [Iris Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/iris.arff)\n",
        "\n",
        "### 2.1 (10%) Iris Clustering with HAC\n",
        "\n",
        "- Use single-link and complete link clustering algorithms\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SSoasDQSKXb"
      },
      "outputs": [],
      "source": [
        "# Iris Clustering using single-link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrxjOxay-Jep"
      },
      "outputs": [],
      "source": [
        "# Iris Clustering using complete-link"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjkatnQY-Jep"
      },
      "source": [
        "Discuss your results including the differences between single-link and complete-link"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGfrL7p5-Jeq"
      },
      "source": [
        "### 2.2 (10%) Iris Clustering with K-means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gigfanaW-Jeq"
      },
      "outputs": [],
      "source": [
        "# Iris Clustering with K-means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IELq_zlu-Jeq"
      },
      "source": [
        "Discuss your results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVA-r3WV-Jeq"
      },
      "source": [
        "### 2.3 (5%) K-means Initial Centroids Experiment\n",
        "\n",
        "- Run K-means 5 times with *k*=4, each time with different initial random centroids and discuss any variations in the results.\n",
        "- If you ever end up with any empty clusters in K-means, re-run with different initial centroids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtXU14fU-Jer"
      },
      "outputs": [],
      "source": [
        "#K-means 5 times"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7LlyNEZ-Jer"
      },
      "source": [
        "Discuss any variations in the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBBmeNQ7jvcQ"
      },
      "source": [
        "## 3. Scikit-Learn Comparison\n",
        "\n",
        "### 3.1 (10%) Run the SK versions of HAC (just single link) and K-means on Iris data set above\n",
        "\n",
        "- Report results for a couple values of *k*\n",
        "- Experiment using different hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFQv70W2VyqJ"
      },
      "outputs": [],
      "source": [
        "# Load sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqSFAXwlk3Ms"
      },
      "source": [
        "*Discuss Results and Comparison with your versions of the algorithms. Discuss effects of different hyperparameters*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWXyGtuk-Jer"
      },
      "source": [
        "### 3.2 (10%) Run the SK version of HAC (just single link) and K-means on a dataset of your choice \n",
        "- Report results for a couple values of *k*\n",
        "- Experiment using different hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iu510dby-Jer"
      },
      "outputs": [],
      "source": [
        "# Load sklearn "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-oKHPPT-Jer"
      },
      "source": [
        "*Discussion*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTlK-kijk8Mg"
      },
      "source": [
        "## 4. (Optional 5% extra credit) Write your own code for silhouette\n",
        "If you do this option implement your code for silhouette above in your main implementation and use it for your experiments. Make it clear that the silhouette results come from your code. You may/should compare with the SK version to debug/verify your results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtWj9ej2-Jes"
      },
      "source": [
        "*Discussion*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
